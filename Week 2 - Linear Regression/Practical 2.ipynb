{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Data Mining 2017 (Spring) - Practical 2: Know your Predictions\n",
    "\n",
    "This session will focus on making precitions, ascertaining the correctness of these predictions, and trying to party improve them. You are going to use the **IMDB 5000 Movie Dataset**.\n",
    "\n",
    "- Information: [task & data](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset)\n",
    "- Data: [link](https://raw.githubusercontent.com/tcsai/social-data-mining/master/data/imdb.csv)\n",
    "\n",
    "Again: please make sure you understand the dataset and the task before beginning. In this practical we will focus on predictive regression. Apart from getting to know our data, we want to try and solve the task we are assigned.\n",
    "\n",
    "---\n",
    "\n",
    "![img1](https://kaggle2.blob.core.windows.net/datasets-images/138/287/229bfb5d3dd1a49cc5ac899c45ca2213/dataset-cover.png)\n",
    "\n",
    "## 1 - Interpreting the Data\n",
    "\n",
    "The IMDB dataset is scraped off the internet and as-is. Please note that the provided version has an extra feature: `quality`. This was built up from the IMDB score, and structured as follows:\n",
    "\n",
    "    1-3:  very bad\n",
    "    3-5:  bad\n",
    "    5-7:  okay\n",
    "    7-8:  good\n",
    "    8-10: very good\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- Which prediction tasks can you come up with given this dataset?\n",
    "- Inspect the raw data; can you see problems with it?\n",
    "- Visualize the year * budget and label the instances by movie title. What movie has the highest budget?\n",
    "- Look up the movie; is the information correct?\n",
    "\n",
    "---\n",
    "\n",
    "![imgproc](https://image.slidesharecdn.com/datapreprocessing-150127194908-conversion-gate01/95/data-preprocessing-3-638.jpg?cb=1422388220)\n",
    "\n",
    "## 2 - Preprocessing\n",
    "\n",
    "Data can be noisy, does not correctly represent what we want it to, and therefore hampers the tools that we are using. In Orange's case; some information (such as that in the visualizations) can show up incorrectly if no proper preprocessing is conducted beforehand. This is done with the `Preprocessing` widget; generally placed between your data and anything else. In it, several options are presented which can be dragged to the right side of the screen to activate. For now, we will only focus on `Impute`.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- Remove any items in the list on the right.\n",
    "- Select Impute Missing Values. Consider the options. Which one would you prefer given this dataset?\n",
    "- Does the information now plot correctly?\n",
    "\n",
    "---\n",
    "\n",
    "![imgfilter](https://upload.wikimedia.org/wikipedia/commons/2/25/Crystal_Project_Filter.png)\n",
    "\n",
    "\n",
    "\n",
    "## 3 - Filtering Features\n",
    "\n",
    "Given that we've also established issues with some of the features, it would be preferable if we filter them based on these specifications. You can select features based on some rule in the `Select Rows` widget. In turn, you can set up the prediction task as determined in the first task by using the `Select Columns` widget (both under Data). These should be changed **after** eachother.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- Filter movies to be USA only.\n",
    "- Remove any features that can't be determined pre-release.\n",
    "- How do you think certain features affect predictions? What would including `quality` do, specifically?\n",
    "- How did your prediction set-up change?\n",
    "\n",
    "---\n",
    "\n",
    "![imgreg](http://www.vias.org/science_cartoons/img/gm_regression.jpg)\n",
    "\n",
    "\n",
    "## 3 - Prediction\n",
    "\n",
    "To apply Linear Regression to our data, we use the `Linear Regression` widget (found under Regression). Chain the widget after your filtering components. You can use the `Data Table` widget (again changed after) to interepret the coefficients and the bias. Under Evaluate, you can find the `Test & Score` widget. Input both your data (from `Select Columns`), as well as your model (from `Linear Regression`) to this. \n",
    "\n",
    "![imgtest](http://scott.fortmann-roe.com/docs/docs/MeasuringError/holdout.png)\n",
    "\n",
    "The scores will give you an estimate of the erros on our data. We go into detail about this topic in the next lecture. However, for now it's good to know that to get these scores, the model first tries to computationally fit the best possible regression line on some part of the data (the training data). Once this is determined, it is provided with a set of new, unseen data (test data), and asked to make predictions on these. It then computes the error. Further insight into this process is given in section 5.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- Do the coefficients give you any information?\n",
    "- How can you interpret the error scores?\n",
    "\n",
    "---\n",
    "\n",
    "![imgana](https://inquiryintoinquiry2012.files.wordpress.com/2012/11/analysis1.jpg)\n",
    "\n",
    "\n",
    "## 4 - Interpreting Scores\n",
    "\n",
    "One way to determine feature importance for regression is to gradually increase the amount of features used in the model, and see how they individually decrease the error rates. For this, we also need some form of **baseline**: a 'stupid' method of prediction to compare against. For regression, we generally use the `Mean Learner` widget (computes the average over all scores, and always predicts this for each instance). Connect the `Mean Learner` to `Test & Score`; it should show up as well.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- Use the `Select Columns` widget you chained before to remove all but 1 feature, interpret test & score, add 1 feature, interpret, repeat.\n",
    "- What is the most informative feature in this regression?\n",
    "\n",
    "---\n",
    "\n",
    "![imghouse](https://archive.ics.uci.edu/ml/assets/MLimages/Large48.jpg)\n",
    "\n",
    "## 5 - Take Home Assignment: Housing & Predictions\n",
    "\n",
    "This assignmed used the **UCI Housing Dataset** as data. More info can be found [here](https://archive.ics.uci.edu/ml/datasets/Housing).\n",
    "\n",
    "The coefficients and bias per feature fitted by a regression model on **training data** are as follows:\n",
    "\n",
    "```\n",
    "     -0.1084 * crime-rate +\n",
    "      0.0458 * zoned +\n",
    "      2.7187 * charles +\n",
    "    -17.376  * nitric-oxide +\n",
    "      3.8016 * rooms +\n",
    "     -1.4927 * employment-center +\n",
    "      0.2996 * radial-highways +\n",
    "     -0.0118 * property-tax +\n",
    "     -0.9465 * pupil-teach-ratio +\n",
    "      0.0093 * proportion-black-families +\n",
    "     -0.5226 * poor-people +\n",
    "     36.3411\n",
    "```\n",
    "\n",
    "You are provided with the following test data:\n",
    "\n",
    "| crime-rate | zoned | industry | charles | nitric-oxide | rooms | age | employment-center | radial-highways | property-tax | pupil-teach-ratio | proportion-black-families | poor-people |\n",
    "| ---      | ---  | ---    | - | ---    | ---    | ---    | ---    | ---  | ---   | ---   | ---    | ---   |\n",
    "| 25.04610 | 0.00 | 18.100 | 0 | 0.6930 | 5.9870 | 100.00 | 1.5888 | 24   | 666.0 | 20.20 | 396.90 | 26.77 | \n",
    "| 14.23620 | 0.00 | 18.100 | 0 | 0.6930 | 6.3430 | 100.00 | 1.5741 | 24   | 666.0 | 20.20 | 396.90 | 20.32 | \n",
    "| 9.59571  | 0.00 | 18.100 | 0 | 0.6930 | 6.4040 | 100.00 | 1.6390 | 24   | 666.0 | 20.20 | 376.11 | 20.31 | \n",
    "\n",
    "- Use the given formula to predict the `median-value` (by hand) for the feature vectors above.\n",
    "\n",
    "Given these **actual** median values (so the actual price of the houses):\n",
    "\n",
    "| median-value |\n",
    "|------------- |\n",
    "| 5.60         |\n",
    "| 7.20         |\n",
    "| 12.10        |\n",
    "\n",
    "\n",
    "- Use the predicted `median-value` to calculate the Root Mean Squared Error for the **actual** median-value in the table above. You do this by (for each of the feature vectors) substracting the `actual` ($y_t$) from the `predicted` ($\\hat{y_t}$) value, and squaring them. After, you take the sum over all these values (should be 3 values, because 3 instances), divide it by the amount of predictions (3), and take the root of this number. <br><br> Or: <br><br> $\\text{RMSE} = \\sqrt{ \\frac{ \\sum^n_{t=1}(\\hat{y}_t - y_t)^2}{n}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
